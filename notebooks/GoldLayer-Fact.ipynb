{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49f4e691-865d-442a-9d11-c1a5be57571c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDD47 Incremental Load of the `FactSales` Fact Table\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook implements an **incremental process** to populate the `FactSales` fact table in the `gold` schema, using data from the `silver` schema.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26852017-9e16-4d01-a61c-e9505c1f4f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Process Parameter Configuration\n",
    "This cell defines the configuration variables required to run the process.  \n",
    "Each parameter controls how and where data will be extracted and loaded.\n",
    "\n",
    "- **`catalog`**  \n",
    "  - Name of the Spark catalog or database where the tables reside.  \n",
    "  - Usually corresponds to the current workspace or execution context in Databricks or another compatible platform.  \n",
    "\n",
    "- **`cdc_col`**  \n",
    "  - Column used as **Change Data Capture** (CDC).  \n",
    "  - Indicates the date and time of the last modification for each record, and is used to filter only new or updated data.  \n",
    "\n",
    "- **`backdate_refresh`**  \n",
    "  - Optional field to force a reload starting from a specific date.  \n",
    "  - If empty (`\"\"`), the last load date detected in the target will be used.  \n",
    "  - If a date is provided (`\"YYYY-MM-DD HH:MM:SS\"`), it will be used as the starting point to reload data.\n",
    "\n",
    "- **`source_object`**  \n",
    "  - Name of the **source** fact table in the *silver* zone.  \n",
    "\n",
    "- **`source_schema`**  \n",
    "  - Name of the schema where the source fact table is located (*silver layer*).  \n",
    "\n",
    "- **`target_schema`**  \n",
    "  - Name of the schema where the target fact table will be stored (*gold layer*).  \n",
    "\n",
    "- **`target_object`**  \n",
    "  - Name of the **target** fact table in the *gold* zone.  \n",
    "\n",
    "- **`fact_key`**  \n",
    "  - Name of the fact table key.  \n",
    "  - Used as a unique identifier to perform *upserts* in Delta Lake (MERGE between source and target).  \n",
    "  - Leave empty (`\"\"`) if the fact table does not have one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92e5cb7b-bda1-4c2b-9593-9d3810976c6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"workspace\"\n",
    "cdc_col  = \"modified_date\"\n",
    "backdate_refresh = \"\"\n",
    "source_object = \"silver_sales\"\n",
    "source_schema = \"silver\"\n",
    "target_schema = \"gold\"\n",
    "target_object = \"FactSales\"\n",
    "fact_key = \"sales_sk\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "035d0f7b-323c-4ea8-bda9-0e8707bf2de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- **`dimensions`**  \n",
    "  - List of dictionaries with the configuration of each dimension to be joined to the fact table.  \n",
    "  - Each element includes:  \n",
    "    - **`table`** → Full name of the dimension table (including catalog and schema).  \n",
    "    - **`alias`** → Alias to be used in SQL when referring to the dimension.  \n",
    "    - **`join_keys`** → List of tuples indicating the join columns between the fact table and the dimension.  \n",
    "      - Each tuple has the format `(fact_col, dim_col)` where:  \n",
    "        - `fact_col` is the column in the fact table.  \n",
    "        - `dim_col` is the column in the dimension table.  \n",
    "    - **`surrogate_key`** → Surrogate key column of the dimension that should be selected in the `SELECT` statement.  \n",
    "\n",
    "- **`fact_table`**  \n",
    "  - Full path of the source fact table.\n",
    "\n",
    "- **`fact_columns`**  \n",
    "  - List of column names to be extracted directly from the fact table during the incremental query, excluding foreign keys to dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09993f3e-b8ea-4ae3-a832-ece4872b6aeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimProducts\",\n",
    "        \"alias\": \"DimProducts\",\n",
    "        \"join_keys\": [(\"product_sk\", \"product_sk\")], # (fact_col, dim_col)\n",
    "        \"surrogate_key\": \"product_sk\"\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimStores\",\n",
    "        \"alias\": \"DimStores\",\n",
    "        \"join_keys\": [(\"store_sk\", \"store_sk\")], \n",
    "        \"surrogate_key\": \"store_sk\"\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimSalesPersons\",\n",
    "        \"alias\": \"DimSalesPersons\",\n",
    "        \"join_keys\": [(\"salesperson_sk\", \"salesperson_sk\")],\n",
    "        \"surrogate_key\": \"salesperson_sk\"\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimTimes\",\n",
    "        \"alias\": \"DimTimes\",\n",
    "        \"join_keys\": [(\"time_sk\", \"time_sk\")],\n",
    "        \"surrogate_key\": \"time_sk\"\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimDates\",\n",
    "        \"alias\": \"DimDates\",\n",
    "        \"join_keys\": [(\"date_sk\", \"date_sk\")],\n",
    "        \"surrogate_key\": \"date_sk\"\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimCustomers\",\n",
    "        \"alias\": \"DimCustomers\",\n",
    "        \"join_keys\": [(\"customer_sk\", \"customer_sk\")],\n",
    "        \"surrogate_key\": \"customer_sk\"\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimCampaigns\",\n",
    "        \"alias\": \"DimCampaigns\",\n",
    "        \"join_keys\": [(\"campaign_sk\", \"campaign_sk\")],\n",
    "        \"surrogate_key\": \"campaign_sk\"\n",
    "    }\n",
    "]\n",
    "\n",
    "fact_table = f\"{catalog}.{source_schema}.{source_object}\"\n",
    "\n",
    "fact_columns = [\"sales_sk\", \"sales_id\", \"total_amount\", \"modified_date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71ec7b42-e2f6-41a1-9f0d-6f12bd1f23b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Calculates the cutoff date for the incremental load.  \n",
    "- **If `backdate_refresh` is empty** (`\"\"`):  \n",
    "  - Checks if the target table (`target_schema.target_object`) exists in the Spark catalog.  \n",
    "    - **If it exists** → Executes a SQL query to get the maximum value of the `cdc_col` (`modified_date`) in the target table and assigns it to `last_load`.  \n",
    "    - **If it does not exist** → Assigns the date `\"1900-01-01 00:00:00\"` to force a full load.  \n",
    "- **If `backdate_refresh` has a value**:  \n",
    "  - Uses that value directly as `last_load`, without calculating it from the target table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b48ef5c7-d5e0-41e4-ab69-386a4a54c9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if len(backdate_refresh) == 0:\n",
    "    if spark.catalog.tableExists(f\"{target_schema}.{target_object}\"):\n",
    "        last_load = spark.sql(f\"select max({cdc_col}) from workspace.{target_schema}.{target_object}\").collect()[0][0]\n",
    "    else:\n",
    "        last_load = \"1900-01-01 00:00:00\"\n",
    "else:\n",
    "    last_load = backdate_refresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a62f6a-e94a-424c-afc3-14f67831a36e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**`generate_fact_query_incremental`**  \n",
    "Builds the SQL query that retrieves only the new or updated records from the fact table and enriches them with dimension data.  \n",
    "\n",
    "**How it works**:  \n",
    "- Assigns alias `\"f\"` to the fact table to simplify the SQL.  \n",
    "- Constructs the list of columns to select:  \n",
    "  - All columns defined in `fact_columns` (from the fact table).  \n",
    "  - The surrogate key of each dimension (from `join_keys`).  \n",
    "- For each dimension:  \n",
    "  - Generates a `LEFT JOIN` using the columns defined in `join_keys`.  \n",
    "- Creates the `WHERE` clause filtering records where `cdc_column >= processing_date`.  \n",
    "- Returns the SQL query ready to execute in Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "586c3d8f-0159-4e00-b689-cb5e98549ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_fact_query_incremental(fact_table, dimensions, fact_columns, cdc_column, processing_date):\n",
    "    fact_alias = \"f\"\n",
    "\n",
    "    select_cols = [f\"{fact_alias}.{col}\" for col in fact_columns]\n",
    "    join_clauses = []\n",
    "\n",
    "    for dim in dimensions:\n",
    "        table_full = dim[\"table\"]\n",
    "        alias = dim[\"alias\"]\n",
    "        table_name = table_full.split('.')[-1]\n",
    "\n",
    "        fact_col, dim_col = dim[\"join_keys\"][0]\n",
    "\n",
    "        surrogate_key = f\"{alias}.{dim['surrogate_key']}\"\n",
    "\n",
    "        select_cols.append(surrogate_key)\n",
    "\n",
    "        on_conditions = [f\"{fact_alias}.{fk} = {alias}.{dk}\" for fk, dk in dim[\"join_keys\"]]\n",
    "        join_clause = f\"LEFT JOIN {table_full} {alias} ON \" + \" AND \".join(on_conditions)\n",
    "        join_clauses.append(join_clause)\n",
    "\n",
    "    select_clause = \",\\n       \".join(select_cols)\n",
    "    joins = \"\\n\".join(join_clauses)\n",
    "    where_clause = f\"{fact_alias}.{cdc_column} >= DATE('{processing_date}')\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT {select_clause}\n",
    "    FROM {fact_table} {fact_alias}\n",
    "    {joins}\n",
    "    WHERE {where_clause}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "826d0a76-670d-452a-8ee1-dcefdad17201",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT f.sales_sk,\n       f.sales_id,\n       f.total_amount,\n       f.modified_date,\n       DimProducts.product_sk,\n       DimStores.store_sk,\n       DimSalesPersons.salesperson_sk,\n       DimTimes.time_sk,\n       DimDates.date_sk,\n       DimCustomers.customer_sk,\n       DimCampaigns.campaign_sk\n    FROM workspace.silver.silver_sales f\n    LEFT JOIN workspace.gold.DimProducts DimProducts ON f.product_sk = DimProducts.product_sk\nLEFT JOIN workspace.gold.DimStores DimStores ON f.store_sk = DimStores.store_sk\nLEFT JOIN workspace.gold.DimSalesPersons DimSalesPersons ON f.salesperson_sk = DimSalesPersons.salesperson_sk\nLEFT JOIN workspace.gold.DimTimes DimTimes ON f.time_sk = DimTimes.time_sk\nLEFT JOIN workspace.gold.DimDates DimDates ON f.date_sk = DimDates.date_sk\nLEFT JOIN workspace.gold.DimCustomers DimCustomers ON f.customer_sk = DimCustomers.customer_sk\nLEFT JOIN workspace.gold.DimCampaigns DimCampaigns ON f.campaign_sk = DimCampaigns.campaign_sk\n    WHERE f.modified_date >= DATE('2025-08-19 21:02:11.048000')\n"
     ]
    }
   ],
   "source": [
    "query = generate_fact_query_incremental(fact_table, dimensions, fact_columns, cdc_col, last_load)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e04084b-1969-4544-8828-860f0ebb1b0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The result is loaded into a DataFrame (`df_fact`), which contains:  \n",
    "    - The incremental records of the fact table.  \n",
    "    - The surrogate keys of the joined dimensions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "178538fe-cbc6-43a7-85d2-dc7e82726902",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fact = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd9b6b7-5667-4282-9483-fee34077c700",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755009838079}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sales_sk</th><th>sales_id</th><th>total_amount</th><th>modified_date</th><th>product_sk</th><th>store_sk</th><th>salesperson_sk</th><th>time_sk</th><th>date_sk</th><th>customer_sk</th><th>campaign_sk</th></tr></thead><tbody><tr><td>1</td><td>SALES_0000001</td><td>2421.54</td><td>2025-08-19T18:16:31.999Z</td><td>167</td><td>191</td><td>1442</td><td>929</td><td>50</td><td>56504</td><td>3</td></tr><tr><td>2</td><td>SALES_0000002</td><td>2487.22</td><td>2025-08-19T18:16:31.999Z</td><td>100</td><td>422</td><td>1996</td><td>548</td><td>74</td><td>59945</td><td>8</td></tr><tr><td>3</td><td>SALES_0000003</td><td>2915.91</td><td>2025-08-19T18:16:31.999Z</td><td>71</td><td>411</td><td>1388</td><td>831</td><td>276</td><td>54709</td><td>35</td></tr><tr><td>4</td><td>SALES_0000004</td><td>4086.9</td><td>2025-08-19T18:16:31.999Z</td><td>137</td><td>242</td><td>1211</td><td>1218</td><td>127</td><td>77739</td><td>6</td></tr><tr><td>5</td><td>SALES_0000005</td><td>2425.33</td><td>2025-08-19T18:16:31.999Z</td><td>207</td><td>380</td><td>570</td><td>1330</td><td>236</td><td>97840</td><td>19</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "SALES_0000001",
         2421.54,
         "2025-08-19T18:16:31.999Z",
         167,
         191,
         1442,
         929,
         50,
         56504,
         3
        ],
        [
         2,
         "SALES_0000002",
         2487.22,
         "2025-08-19T18:16:31.999Z",
         100,
         422,
         1996,
         548,
         74,
         59945,
         8
        ],
        [
         3,
         "SALES_0000003",
         2915.91,
         "2025-08-19T18:16:31.999Z",
         71,
         411,
         1388,
         831,
         276,
         54709,
         35
        ],
        [
         4,
         "SALES_0000004",
         4086.9,
         "2025-08-19T18:16:31.999Z",
         137,
         242,
         1211,
         1218,
         127,
         77739,
         6
        ],
        [
         5,
         "SALES_0000005",
         2425.33,
         "2025-08-19T18:16:31.999Z",
         207,
         380,
         570,
         1330,
         236,
         97840,
         19
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sales_sk",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sales_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_amount",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "modified_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "product_sk",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "store_sk",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "salesperson_sk",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "time_sk",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "date_sk",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "customer_sk",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "campaign_sk",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_fact.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6ae07e-4b7f-4d0d-9164-1d01fd54d105",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Loading Data into the Target Table (`FactSales`)**  \n",
    "\n",
    "- **If the target table exists**  \n",
    "  1. It is obtained as a Delta object (`dlt_object`).  \n",
    "  2. A **MERGE** is executed between:\n",
    "     - **`src`** → incremental DataFrame (`df_fact`).\n",
    "     - **`trg`** → target table.\n",
    "  3. MERGE conditions:\n",
    "     - **Match by fact key**\n",
    "     - **When matched** → update all columns if `modified_date` in `src` is greater than or equal to that in `trg`.\n",
    "     - **When not matched** → insert the full record.\n",
    "\n",
    "- **If the target table does not exist**  \n",
    "  → It is created by writing `df_fact` in Delta format, in `append` mode.\n",
    "\n",
    "Usually, we do not perform an Upsert on the fact table, but sometimes it is important, so we keep it. Ideally, only new records should arrive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5dd1584-57c0-487a-8e33-c6e5a4abc5b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ac57bd-e064-4bae-8bbd-9ea0bc37b8cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(f\"{catalog}.{target_schema}.{target_object}\"):\n",
    "    dlt_object = DeltaTable.forName(spark, f\"{catalog}.{target_schema}.{target_object}\")\n",
    "    dlt_object.alias(\"trg\").merge(df_fact.alias(\"src\"), f\"src.{fact_key} = trg.{fact_key}\")\\\n",
    "        .whenMatchedUpdateAll(condition = f\"src.{cdc_col} >= trg.{cdc_col}\")\\\n",
    "        .whenNotMatchedInsertAll()\\\n",
    "        .execute()\n",
    "else:\n",
    "    df_fact.write.format(\"delta\")\\\n",
    "        .mode(\"append\")\\\n",
    "        .saveAsTable(f\"{catalog}.{target_schema}.{target_object}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24d3c3e4-9f2c-4754-a06a-5484db4f744c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If there is no key in the fact table, we can use the combination of all surrogate keys:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d672f37-db75-494c-8c1a-4e71272eea39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If the fact table doesn't have an ID (example: sales_id, sales_sk):\n",
    "# fact_key_cols = [\"customer_sk\",\"product_sk\",\"store_sk\", \n",
    "#                  \"sales_person_sk\",\"campaign_sk\",\"date_sk\",\"time_sk\"]\n",
    "\n",
    "#fact_key_cols_str = \" AND \".join([f\"src.{col} = trg.{col}\" for col in fact_key_cols])\n",
    "#print(fact_key_cols_str)\n",
    "\n",
    "# if spark.catalog.tableExists(f\"{catalog}.{target_schema}.{target_object}\"):\n",
    "#     dlt_object = DeltaTable.forName(spark, f\"{catalog}.{target_schema}.{target_object}\")\n",
    "#     dlt_object.alias(\"trg\").merge(df_fact.alias(\"src\"), fact_key_cols_str)\\\n",
    "#         .whenMatchedUpdateAll(condition = f\"src.{cdc_col} >= trg.{cdc_col}\")\\\n",
    "#         .whenNotMatchedInsertAll()\\\n",
    "#         .execute()\n",
    "# else:\n",
    "#     df_fact.write.format(\"delta\")\\\n",
    "#         .mode(\"append\")\\\n",
    "#         .saveAsTable(f\"{catalog}.{target_schema}.{target_object}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8981209058263329,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "GoldLayer-Fact",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
